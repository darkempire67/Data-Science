{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age Gender     ChestPain  RestBP  Chol  RestECG  MaxHR  Oldpeak  \\\n",
      "0     63      f       typical     145   233        2    150      2.3   \n",
      "1     67      f  asymptomatic     160   286        2    108      1.5   \n",
      "2     67      f  asymptomatic     120   229        2    129      2.6   \n",
      "3     37      f    nonanginal     130   250        0    187      3.5   \n",
      "4     41      m    nontypical     130   204        2    172      1.4   \n",
      "5     56      f    nontypical     120   236        0    178      0.8   \n",
      "6     62      m  asymptomatic     140   268        2    160      3.6   \n",
      "7     57      m  asymptomatic     120   354        0    163      0.6   \n",
      "8     63      f  asymptomatic     130   254        2    147      1.4   \n",
      "9     53      f  asymptomatic     140   203        2    155      3.1   \n",
      "10    57      f  asymptomatic     140   192        0    148      0.4   \n",
      "11    56      m    nontypical     140   294        2    153      1.3   \n",
      "12    56      f    nonanginal     130   256        2    142      0.6   \n",
      "13    44      f    nontypical     120   263        0    173      0.0   \n",
      "14    52      f    nonanginal     172   199        0    162      0.5   \n",
      "15    57      f    nonanginal     150   168        0    174      1.6   \n",
      "16    48      f    nontypical     110   229        0    168      1.0   \n",
      "17    54      f  asymptomatic     140   239        0    160      1.2   \n",
      "18    48      m    nonanginal     130   275        0    139      0.2   \n",
      "19    49      f    nontypical     130   266        0    171      0.6   \n",
      "20    64      f       typical     110   211        2    144      1.8   \n",
      "21    58      m       typical     150   283        2    162      1.0   \n",
      "22    58      f    nontypical     120   284        2    160      1.8   \n",
      "23    58      f    nonanginal     132   224        2    173      3.2   \n",
      "24    60      f  asymptomatic     130   206        2    132      2.4   \n",
      "25    50      m    nonanginal     120   219        0    158      1.6   \n",
      "26    58      m    nonanginal     120   340        0    172      0.0   \n",
      "27    66      m       typical     150   226        0    114      2.6   \n",
      "28    43      f  asymptomatic     150   247        0    171      1.5   \n",
      "29    40      f  asymptomatic     110   167        2    114      2.0   \n",
      "..   ...    ...           ...     ...   ...      ...    ...      ...   \n",
      "273   71      m  asymptomatic     112   149        0    125      1.6   \n",
      "274   59      f       typical     134   204        0    162      0.8   \n",
      "275   64      f       typical     170   227        2    155      0.6   \n",
      "276   66      m    nonanginal     146   278        2    152      0.0   \n",
      "277   39      m    nonanginal     138   220        0    152      0.0   \n",
      "278   57      f    nontypical     154   232        2    164      0.0   \n",
      "279   58      m  asymptomatic     130   197        0    131      0.6   \n",
      "280   57      f  asymptomatic     110   335        0    143      3.0   \n",
      "281   47      f    nonanginal     130   253        0    179      0.0   \n",
      "282   55      m  asymptomatic     128   205        1    130      2.0   \n",
      "283   35      f    nontypical     122   192        0    174      0.0   \n",
      "284   61      f  asymptomatic     148   203        0    161      0.0   \n",
      "285   58      f  asymptomatic     114   318        1    140      4.4   \n",
      "286   58      m  asymptomatic     170   225        2    146      2.8   \n",
      "287   58      f    nontypical     125   220        0    144      0.4   \n",
      "288   56      f    nontypical     130   221        2    163      0.0   \n",
      "289   56      f    nontypical     120   240        0    169      0.0   \n",
      "290   67      f    nonanginal     152   212        2    150      0.8   \n",
      "291   55      m    nontypical     132   342        0    166      1.2   \n",
      "292   44      f  asymptomatic     120   169        0    144      2.8   \n",
      "293   63      f  asymptomatic     140   187        2    144      4.0   \n",
      "294   63      m  asymptomatic     124   197        0    136      0.0   \n",
      "295   41      f    nontypical     120   157        0    182      0.0   \n",
      "296   59      f  asymptomatic     164   176        2     90      1.0   \n",
      "297   57      m  asymptomatic     140   241        0    123      0.2   \n",
      "298   45      f       typical     110   264        0    132      1.2   \n",
      "299   68      f  asymptomatic     144   193        0    141      3.4   \n",
      "300   57      f  asymptomatic     130   131        0    115      1.2   \n",
      "301   57      m    nontypical     130   236        2    174      0.0   \n",
      "302   38      f    nonanginal     138   175        0    173      0.0   \n",
      "\n",
      "           Thal  AHD  \n",
      "0         fixed   No  \n",
      "1        normal  Yes  \n",
      "2    reversable  Yes  \n",
      "3        normal   No  \n",
      "4        normal   No  \n",
      "5        normal   No  \n",
      "6        normal  Yes  \n",
      "7        normal   No  \n",
      "8    reversable  Yes  \n",
      "9    reversable  Yes  \n",
      "10        fixed   No  \n",
      "11       normal   No  \n",
      "12        fixed  Yes  \n",
      "13   reversable   No  \n",
      "14   reversable   No  \n",
      "15       normal   No  \n",
      "16   reversable  Yes  \n",
      "17       normal   No  \n",
      "18       normal   No  \n",
      "19       normal   No  \n",
      "20       normal   No  \n",
      "21       normal   No  \n",
      "22       normal  Yes  \n",
      "23   reversable  Yes  \n",
      "24   reversable  Yes  \n",
      "25       normal   No  \n",
      "26       normal   No  \n",
      "27       normal   No  \n",
      "28       normal   No  \n",
      "29   reversable  Yes  \n",
      "..          ...  ...  \n",
      "273      normal   No  \n",
      "274      normal  Yes  \n",
      "275  reversable   No  \n",
      "276      normal   No  \n",
      "277      normal   No  \n",
      "278      normal  Yes  \n",
      "279      normal   No  \n",
      "280  reversable  Yes  \n",
      "281      normal   No  \n",
      "282  reversable  Yes  \n",
      "283      normal   No  \n",
      "284  reversable  Yes  \n",
      "285       fixed  Yes  \n",
      "286       fixed  Yes  \n",
      "287  reversable   No  \n",
      "288  reversable   No  \n",
      "289      normal   No  \n",
      "290  reversable  Yes  \n",
      "291      normal   No  \n",
      "292       fixed  Yes  \n",
      "293  reversable  Yes  \n",
      "294      normal  Yes  \n",
      "295      normal   No  \n",
      "296       fixed  Yes  \n",
      "297  reversable  Yes  \n",
      "298  reversable  Yes  \n",
      "299  reversable  Yes  \n",
      "300  reversable  Yes  \n",
      "301      normal  Yes  \n",
      "302      normal   No  \n",
      "\n",
      "[303 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# ---------part-A QUESTION 1 Predicting Heart Disease-------------------------------------------\n",
    "# Importing the required packages and libraries\n",
    "# we will need numpy and pandas later\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#read from drive\n",
    "heart_df= pd.read_csv('/Users/crisramos/Desktop/Data Science/Data Sets/Heart_s.csv')\n",
    "# ---part B\n",
    "print(heart_df)\n",
    "\n",
    "# ---------part-C\n",
    "\n",
    "no_cat_feats=['Age',  'RestBP', 'Chol', 'RestECG', 'MaxHR',\n",
    "       'Oldpeak']\n",
    "\n",
    "X=heart_df[no_cat_feats]\n",
    "\n",
    "y =heart_df['AHD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------part-D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, \n",
    "                                                    random_state=4)\n",
    "# above we split ds to  match 'test_size=0.25, random_state=4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy of knn': 0.6447368421052632, 'accuracy of DT': 0.618421052631579, 'accuracy of LR': 0.7368421052631579}\n"
     ]
    }
   ],
   "source": [
    "# ----------part E\n",
    "#import all methods of predictting KNN Logistic Regression Decission Tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "results={}\n",
    "#train n test accuracy\n",
    "#knn goes first\n",
    "my_knn=KNeighborsClassifier(n_neighbors=3)\n",
    "my_knn.fit(X_train,y_train)\n",
    "y_predict_knn=my_knn.predict(X_test)\n",
    "results['accuracy of knn']=accuracy_score(y_test,y_predict_knn)\n",
    "\n",
    "#Decision Tree second\n",
    "my_decisiontree = DecisionTreeClassifier(random_state=5)\n",
    "my_decisiontree.fit(X_train, y_train)\n",
    "y_predict_dt = my_decisiontree.predict(X_test)\n",
    "results['accuracy of DT']=accuracy_score(y_test,y_predict_dt)\n",
    "\n",
    "#Logistic Regression\n",
    "my_logreg = LogisticRegression()\n",
    "my_logreg.fit(X_train, y_train)\n",
    "y_predict_lr = my_logreg.predict(X_test)\n",
    "results['accuracy of LR']=accuracy_score(y_test,y_predict_lr)\n",
    "\n",
    "#----> Best one is Logistic Regression, worst is Decision Tree.\n",
    "print (results)\n",
    "#print(heart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy of knn-binary': 0.6710526315789473, 'accuracy of DT-binary': 0.6578947368421053, 'accuracy of LR-binary': 0.8157894736842105}\n",
      "{'accuracy of knn': 0.6447368421052632, 'accuracy of DT': 0.618421052631579, 'accuracy of LR': 0.7368421052631579}\n"
     ]
    }
   ],
   "source": [
    "# ------------part-F we will OneHotEncode categorical features----->\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#bin_heart_df defines the new data set using binary categories on \"gender,chestpain and thal\"\n",
    "#using label encoder we will turn categorical features to a binary manner\n",
    "\n",
    "bin_heart_df= pd.read_csv('/Users/crisramos/Desktop/Data Science/Data Sets/Heart_s.csv')\n",
    "#turn gender first\n",
    "le_gender = LabelEncoder()\n",
    "bin_heart_df['gender_encoded'] = le_gender.fit_transform(bin_heart_df.Gender)\n",
    "gender_ohe = OneHotEncoder()\n",
    "Xg = gender_ohe.fit_transform(bin_heart_df.gender_encoded.values.reshape(-1,1)).toarray()\n",
    "#turn chestpain second\n",
    "le_chestp = LabelEncoder()\n",
    "bin_heart_df['chestpain_encoded'] = le_chestp.fit_transform(bin_heart_df.ChestPain)\n",
    "chestpain_ohe = OneHotEncoder()\n",
    "Xcp = chestpain_ohe.fit_transform(bin_heart_df.chestpain_encoded.values.reshape(-1,1)).toarray()\n",
    "#turn thal third\n",
    "le_thal = LabelEncoder()\n",
    "bin_heart_df['thal_encoded'] = le_thal.fit_transform(bin_heart_df['Thal'].astype(str))\n",
    "thal_ohe = OneHotEncoder()\n",
    "Xt = thal_ohe.fit_transform(bin_heart_df.thal_encoded.values.reshape(-1,1)).toarray()\n",
    "\n",
    "#next step put data back in dataframe--->\n",
    "\n",
    "dfOneHot = pd.DataFrame(Xg, columns = [\"Gender-F\",\"Gender-M\"])\n",
    "bin_heart_df = pd.concat([bin_heart_df, dfOneHot], axis=1)\n",
    "dfOneHot = pd.DataFrame(Xcp, columns = [\"ChestPain-Asymptomatic\",\"ChestPain-NonAnginal\",\"ChestPain-NonTypical\",\"ChestPain-Typical\"])\n",
    "bin_heart_df = pd.concat([bin_heart_df, dfOneHot], axis=1)\n",
    "dfOneHot = pd.DataFrame(Xt, columns = [\"Thal fixed\",\"???\",\"Thal normal\",\"Thal reversable\"])\n",
    "del dfOneHot[\"???\"]# i got an extra column idk why, Thal only has 3 Cats. for Thal\n",
    "                    #-so i deleted it unafecting the data because it was empty.\n",
    "bin_heart_df = pd.concat([bin_heart_df, dfOneHot], axis=1)\n",
    "\n",
    "# -----------part-G repeating training except we use new data now with binary features sub---->\n",
    "\n",
    "bin_feats=[\"Gender-F\",\"Gender-M\",\"ChestPain-Asymptomatic\",\"ChestPain-NonAnginal\",\n",
    "           \"ChestPain-NonTypical\",\"ChestPain-Typical\",\"Thal fixed\",\"Thal normal\",\n",
    "           \"Thal reversable\"]\n",
    "bin_feats=bin_feats+no_cat_feats\n",
    "#print(bin_feats)\n",
    "\n",
    "\n",
    "Xbin=bin_heart_df[bin_feats]\n",
    "ybin =bin_heart_df['AHD']\n",
    "#print(Xbin)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xbin_train, Xbin_test, ybin_train, ybin_test = train_test_split(Xbin, ybin, test_size=0.25, \n",
    "                                                    random_state=4)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "results_bin={}\n",
    "#train and test accuracy\n",
    "#knn goes first\n",
    "my_knn_bin=KNeighborsClassifier(n_neighbors=3)\n",
    "my_knn_bin.fit(Xbin_train,ybin_train)\n",
    "y_predict_knn_bin=my_knn_bin.predict(Xbin_test)\n",
    "results_bin['accuracy of knn-binary']=accuracy_score(ybin_test,y_predict_knn_bin)\n",
    "\n",
    "#Decision Tree second\n",
    "my_decisiontree_bin = DecisionTreeClassifier(random_state=5)\n",
    "my_decisiontree_bin.fit(Xbin_train, ybin_train)\n",
    "y_predict_dt_bin = my_decisiontree_bin.predict(Xbin_test)\n",
    "results_bin['accuracy of DT-binary']=accuracy_score(ybin_test,y_predict_dt_bin)\n",
    "\n",
    "#Logistic Regression\n",
    "my_logreg_bin = LogisticRegression()\n",
    "my_logreg_bin.fit(Xbin_train, ybin_train)\n",
    "y_predict_lr_bin = my_logreg_bin.predict(Xbin_test)\n",
    "results_bin['accuracy of LR-binary']=accuracy_score(ybin_test,y_predict_lr_bin)\n",
    "\n",
    "#-------Part G----> This improves the accuracy by turning the categorical to binary columns\n",
    "print (results_bin)\n",
    "print (results)\n",
    "\n",
    "\n",
    "#print(bin_heart_df)\n",
    "#print(Xbin)\n",
    "#print(ybin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy of knn': 0.6447368421052632, 'accuracy of DT': 0.618421052631579, 'accuracy of LR': 0.7368421052631579}\n",
      "\n",
      "\n",
      "{'accuracy of knn-binary': 0.6710526315789473, 'accuracy of DT-binary': 0.6578947368421053, 'accuracy of LR-binary': 0.8157894736842105}\n",
      "\n",
      "\n",
      "{'accuracyX_cv of  KNN ': 0.6141342232109752, 'accuracyX_cv of Decision Tree ': 0.718642936596218, 'accuracyX_cv of Logistic Regression': 0.8115684093437153}\n"
     ]
    }
   ],
   "source": [
    "# --------Part H --- Xvalidation on all three object KNN, DT and LR. and save results--->\n",
    "from sklearn.model_selection import cross_val_score\n",
    "resultsX={}\n",
    "\n",
    "accuracy_list = cross_val_score(my_knn_bin, Xbin, ybin, cv=10, scoring='accuracy')\n",
    "accuracy_cv = accuracy_list.mean()\n",
    "resultsX['accuracyX_cv of  KNN ']=accuracy_cv\n",
    "\n",
    "accuracy_list = cross_val_score(my_decisiontree_bin, Xbin, ybin, cv=10, scoring='accuracy')\n",
    "accuracy_cv = accuracy_list.mean()\n",
    "resultsX['accuracyX_cv of Decision Tree ']=accuracy_cv\n",
    "\n",
    "accuracy_list = cross_val_score(my_logreg_bin, Xbin, ybin, cv=10, scoring='accuracy')\n",
    "accuracy_cv = accuracy_list.mean()\n",
    "resultsX['accuracyX_cv of Logistic Regression']=accuracy_cv\n",
    "\n",
    "\n",
    "# showing all results in order performed.\n",
    "\n",
    "print (results)\n",
    "print('\\n')\n",
    "print (results_bin)\n",
    "print('\\n')\n",
    "print (resultsX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Income  Limit  Rating  Cards  Age  Education  Married  Balance\n",
      "0     14.891   3606     283      2   34         11        1      333\n",
      "1    106.025   6645     483      3   82         15        1      903\n",
      "2    104.593   7075     514      4   71         11        0      580\n",
      "3    148.924   9504     681      3   36         11        0      964\n",
      "4     55.882   4897     357      2   68         16        1      331\n",
      "5     80.180   8047     569      4   77         10        0     1151\n",
      "6     20.996   3388     259      2   37         12        0      203\n",
      "7     71.408   7114     512      2   87          9        0      872\n",
      "8     15.125   3300     266      5   66         13        0      279\n",
      "9     71.061   6819     491      3   41         19        1     1350\n",
      "10    63.095   8117     589      4   30         14        1     1407\n",
      "11    15.045   1311     138      3   64         16        0        0\n",
      "12    80.616   5308     394      1   57          7        1      204\n",
      "13    43.682   6922     511      1   49          9        1     1081\n",
      "14    19.144   3291     269      2   75         13        0      148\n",
      "15    20.089   2525     200      3   57         15        1        0\n",
      "16    53.598   3714     286      3   73         17        1        0\n",
      "17    36.496   4378     339      3   69         15        1      368\n",
      "18    49.570   6384     448      1   28          9        1      891\n",
      "19    42.079   6626     479      2   44          9        0     1048\n",
      "20    17.700   2860     235      4   63         16        0       89\n",
      "21    37.348   6378     458      1   72         17        0      968\n",
      "22    20.103   2631     213      3   61         10        1        0\n",
      "23    64.027   5179     398      5   48          8        1      411\n",
      "24    10.742   1757     156      3   57         15        0        0\n",
      "25    14.090   4323     326      5   25         16        1      671\n",
      "26    42.471   3625     289      6   44         12        0      654\n",
      "27    32.793   4534     333      2   44         16        0      467\n",
      "28   186.634  13414     949      2   41         14        1     1809\n",
      "29    26.813   5611     411      4   55         16        0      915\n",
      "..       ...    ...     ...    ...  ...        ...      ...      ...\n",
      "370   35.610   6135     466      4   40         12        0      992\n",
      "371   39.116   2150     173      4   75         15        0        0\n",
      "372   19.782   3782     293      2   46         16        0      840\n",
      "373   55.412   5354     383      2   37         16        1     1003\n",
      "374   29.400   4840     368      3   76         18        1      588\n",
      "375   20.974   5673     413      5   44         16        1     1000\n",
      "376   87.625   7167     515      2   46         10        0      767\n",
      "377   28.144   1567     142      3   51         10        1        0\n",
      "378   19.349   4941     366      1   33         19        1      717\n",
      "379   53.308   2860     214      1   84         10        1        0\n",
      "380  115.123   7760     538      3   83         14        0      661\n",
      "381  101.788   8029     574      2   84         11        1      849\n",
      "382   24.824   5495     409      1   33          9        0     1352\n",
      "383   14.292   3274     282      9   64          9        1      382\n",
      "384   20.088   1870     180      3   76         16        0        0\n",
      "385   26.400   5640     398      3   58         15        0      905\n",
      "386   19.253   3683     287      4   57         10        0      371\n",
      "387   16.529   1357     126      3   62          9        0        0\n",
      "388   37.878   6827     482      2   80         13        0     1129\n",
      "389   83.948   7100     503      2   44         18        0      806\n",
      "390  135.118  10578     747      3   81         15        1     1393\n",
      "391   73.327   6555     472      2   43         15        0      721\n",
      "392   25.974   2308     196      2   24         10        0        0\n",
      "393   17.316   1335     138      2   65         13        0        0\n",
      "394   49.794   5758     410      4   40          8        0      734\n",
      "395   12.096   4100     307      3   32         13        1      560\n",
      "396   13.364   3838     296      5   65         17        0      480\n",
      "397   57.872   4171     321      5   67         12        1      138\n",
      "398   37.728   2525     192      1   44         13        1        0\n",
      "399   18.701   5524     415      5   64          7        0      966\n",
      "\n",
      "[400 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Question 2 DEbt Prediction ---------------\n",
    "# ---part A-----\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "credit_df= pd.read_csv('/Users/crisramos/Desktop/Data Science/Data Sets/Credit.csv')\n",
    "#part B---show df\n",
    "print(credit_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.86158299 -0.48999879 -0.46553881 ... -1.2576741  -0.78492991\n",
      "   0.79539491]\n",
      " [ 1.72743711  0.82826106  0.82870309 ...  1.5284506   0.49658831\n",
      "   0.79539491]\n",
      " [ 1.68675551  1.01478681  1.02931059 ...  0.88996369 -0.78492991\n",
      "  -1.25723711]\n",
      " ...\n",
      " [ 0.35946155 -0.24491264 -0.21963285 ...  0.65778663 -0.46455035\n",
      "   0.79539491]\n",
      " [-0.21280808 -0.95891584 -1.05441888 ... -0.67723146 -0.1441708\n",
      "   0.79539491]\n",
      " [-0.75334493  0.34199278  0.38866085 ...  0.48365384 -2.06644812\n",
      "  -1.25723711]]\n"
     ]
    }
   ],
   "source": [
    "#part C ---- choose target,isolate vector and normalize features matrix\n",
    "from sklearn import preprocessing\n",
    "\n",
    "c=['Income', 'Limit', 'Rating', 'Cards', 'Age', 'Education', 'Married']\n",
    "#Xc=credit_df[]\n",
    "#print(c)\n",
    "\n",
    "Xc=credit_df[c]\n",
    "yc=credit_df['Balance']\n",
    "Xc=preprocessing.scale(Xc)\n",
    "print(Xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part D ------------split data\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(Xc, yc, test_size=0.24, \n",
    "                                                    random_state=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517.6919750342976\n",
      "[-264.98372644  131.99156792  478.53169403   14.72121881  -29.7832935\n",
      "    1.67827514  -20.20616103]\n",
      "['Income', 'Limit', 'Rating', 'Cards', 'Age', 'Education', 'Married']\n"
     ]
    }
   ],
   "source": [
    "# part -- E ----using Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#create obj\n",
    "my_linreg_credit = LinearRegression()\n",
    "#fitting the model\n",
    "my_linreg_credit.fit(Xc_train, yc_train)\n",
    "\n",
    "# printing Theta0 using attribute \"intercept_\":\n",
    "print(my_linreg_credit.intercept_)\n",
    "\n",
    "# printing [Theta1, Theta2, Theta3] using attribute \"coef_\":\n",
    "print(my_linreg_credit.coef_)\n",
    "\n",
    "print (c) #--part E----> Most importan feature is Income, least important is Credit Rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161.51385491175333\n"
     ]
    }
   ],
   "source": [
    "#part F------\n",
    "yc_prediction = my_linreg_credit.predict(Xc_test)\n",
    "\n",
    "#print(yc_prediction)\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "# Calculating \"Mean Square Error\" (MSE):\n",
    "mse = metrics.mean_squared_error(yc_test, yc_prediction)\n",
    "\n",
    "# Using numpy sqrt function to take the square root and calculate \"Root Mean Square Error\" (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160.3319891074414\n"
     ]
    }
   ],
   "source": [
    "# part G\n",
    "# Applying 10-fold cross validation with \"linear regression\":\n",
    "\n",
    "\n",
    "mse_list = cross_val_score(my_linreg_credit, Xc, yc, cv=10, scoring='neg_mean_squared_error')\n",
    "mse_list_positive = -mse_list\n",
    "#print(mse_list_positive)\n",
    "# using numpy sqrt function to calculate rmse:\n",
    "rmse_list = np.sqrt(mse_list_positive)\n",
    "#print(rmse_list)\n",
    "\n",
    "print(rmse_list.mean())\n",
    "\n",
    "# part G RSME is ==160.3319891074414\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
